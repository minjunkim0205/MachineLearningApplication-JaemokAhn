# Final exam

## 기초 지식(중간고사)  

### 배치 크기: 데이터를 나누는 단위  

### 학습률: 가중치 업데이트 크기  

### 에포크: 데이터 전체 학습 횟수  

### 최적화 함수: 가중치 조정 방법  

### 손실 함수: 예측과 실제 차이 측정  

### 활성화 함수: 뉴런의 출력 결정  

### 지도 학습 (Supervised Learning)

1. **정의**:
   - 지도 학습은 **라벨이 있는** 데이터를 기반으로 모델을 학습하는 방법입니다. 각 입력 데이터에 대해 정답(출력)이 주어집니다.

2. **목적**:
   - 주어진 입력에 대해 올바른 출력을 예측하는 모델을 만드는 것입니다. 즉, 입력과 출력의 관계를 학습합니다.

3. **데이터**:
   - 데이터셋은 입력(features)과 정답(labels)으로 구성되어 있습니다. 예를 들어, 이미지와 그에 대한 레이블(고양이, 개 등)이 포함됩니다.

4. **예시 알고리즘**:
   - 선형 회귀(Linear Regression), 로지스틱 회귀(Logistic Regression), 결정 트리(Decision Trees), 서포트 벡터 머신(SVM), 신경망(Neural Networks) 등.

5. **사용 예**:
   - 이메일 스팸 필터링, 이미지 분류, 주가 예측 등.

### 비지도 학습 (Unsupervised Learning)

1. **정의**:
   - 비지도 학습은 **라벨이 없는** 데이터를 기반으로 모델을 학습하는 방법입니다. 입력 데이터에 대한 정답이 제공되지 않습니다.

2. **목적**:
   - 데이터 내에서 **패턴**이나 **구조**를 찾고, 데이터의 분포를 이해하는 것입니다. 즉, 데이터의 자연스러운 군집화나 연관성을 발견합니다.

3. **데이터**:
   - 데이터셋은 입력(features)만 포함되어 있으며, 정답(labels)은 없습니다. 예를 들어, 고객의 구매 패턴 데이터와 같은 것입니다.

4. **예시 알고리즘**:
   - K-평균 클러스터링(K-Means Clustering), 계층적 클러스터링(Hierarchical Clustering), 주성분 분석(PCA), 오토인코더(Autoencoders) 등.

5. **사용 예**:
   - 고객 세분화, 이미지 압축, 데이터 시각화 등.

### 주요 차이점 요약

| 특성                     | 지도 학습                         | 비지도 학습                       |
|------------------------|----------------------------------|----------------------------------|
| **데이터 라벨**          | 라벨이 있음                       | 라벨이 없음                      |
| **목적**                 | 입력-출력 관계 학습              | 데이터 패턴 및 구조 발견         |
| **예시 알고리즘**        | 선형 회귀, SVM, 신경망 등         | K-평균, PCA, 클러스터링 등        |
| **사용 예**              | 스팸 필터, 이미지 분류            | 고객 세분화, 군집화              |

---

## 시험 공부(기말고사)  

### 데이터 클러스트링  

#### 비지도 학습

- **군집화**:  
    - K-Means, SOM  

- **

# 이거 뭐가 됬던 그냥 아이패드에 정리하는게 더 좋을듯  